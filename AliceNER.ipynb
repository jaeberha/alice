{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad6f1c82",
   "metadata": {},
   "source": [
    "# Asking Questions In \"Alice's Adventures In Wonderland\"\n",
    "\n",
    "## Concerning Nouns And Named Entities\n",
    "\n",
    "### Or \"Falling Down The Rabbit Hole and Getting (A Bit) Confused\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7278c6ca",
   "metadata": {},
   "source": [
    "By Jan Eberhardt, 2/2/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a184e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting started\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0fc3e1",
   "metadata": {},
   "source": [
    "Using SpaCy by Explosion (Ines Montani et al.):\n",
    "    \n",
    "https://github.com/explosion/spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a3b8bc",
   "metadata": {},
   "source": [
    "The source data of \"Alice's Adventures In Wonderland\" is from https://gist.github.com/phillipj/4944029, because of a comment that said:\n",
    "\n",
    "drjoms commented on 23 Feb 2020\n",
    "\n",
    "thanks.\n",
    "was studying regular expression. decided to use the book as sample material.\n",
    "Gutenberg version seemed to add some characters at end of line, which rendered me in state of frustration.\n",
    "your version restored my sanity. thanks!\n",
    "https://gist.github.com/phillipj/4944029?permalink_comment_id=3186160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef1c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basically going through the introduction notebook for text manipulation\n",
    "with open('txt/alice_in_wonderland.txt', 'r', encoding='UTF-8') as f:\n",
    "    text = f.read()\n",
    "    print(text)\n",
    "    print(repr(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7601521",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = text.replace('\\n',' ')\n",
    "print(repr(processed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7039ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = '    ' + processed_text\n",
    "processed_text = processed_text.strip()\n",
    "print(repr(processed_text))\n",
    "text = processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82adf430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = r\"[?]\"\n",
    "\n",
    "matches = re.findall(pattern, text)\n",
    "print (matches)\n",
    "print(len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1efef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to get to the sentences in the text that contain a \"?\"? Trying different regular expressions:\n",
    "re.findall(r\"([^.]*?[^.]*\\?)\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf10ca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"([^.!?]*?[^.?]*\\?)\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2438479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#even trying matche by spacy, but an error occured\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(vocab=nlp.vocab)\n",
    "matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26280500",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionmark = [{'PunctType': 'Peri'}]\n",
    "pattern=[questionmark]\n",
    "matcher.add(\"question\", [questionmark])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74541dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "url = \"https://24.media.tumblr.com/tumblr_m74l2lZ6Y41rb924bo1_r5_500.gif\"\n",
    "response = requests.get(url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42a757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('txt/questions.txt', 'r', encoding='UTF-8') as q:\n",
    "    text = q.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d43c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca78dc0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loop over items in the Doc object, using the variable 'token' to refer to items in the list\n",
    "for token in doc:\n",
    "    \n",
    "    # Print the token and the POS tags\n",
    "    print(token, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c7c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over items in the Doc object\n",
    "# When the tag of the item is a noun, a noun in plural form or a proper noun, write it into a new file\n",
    "# Attention: this file already exists. if you write it again, it adds more nouns to the file\n",
    "for token in doc:\n",
    "    if token.tag_ == 'NN' or token.tag_ == 'NNS' or token.tag_ == 'NNP':\n",
    "        with open(\"txt/nouns.txt\", \"a\") as myfile:\n",
    "            myfile.write(token.text + \"\\n\") \n",
    "            print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dfc5fd",
   "metadata": {},
   "source": [
    "For the visualization of the nouns, I use the Word Cloud repository by Andreas Mueller. He even has a mask looking like Alice and the White Rabbit:\n",
    "\n",
    "https://github.com/amueller/word_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e177d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# get data directory (using getcwd() is needed to support running example in generated IPython notebook)\n",
    "d = path.dirname(__file__) if \"__file__\" in locals() else os.getcwd()\n",
    "\n",
    "# Read the whole text.\n",
    "wctext = open(path.join(d, 'txt/nouns.txt')).read()\n",
    "\n",
    "# read the mask image\n",
    "# taken from\n",
    "# http://www.stencilry.org/stencils/movies/alice%20in%20wonderland/255fk.jpg\n",
    "alice_mask = np.array(Image.open(path.join(d, \"img/alice_mask.png\")))\n",
    "\n",
    "wc = WordCloud(background_color=\"white\", max_words=2000, mask=alice_mask, contour_width=3, contour_color='steelblue')\n",
    "\n",
    "# generate word cloud\n",
    "wc.generate(wctext)\n",
    "\n",
    "# store to file\n",
    "wc.to_file(path.join(d, \"img/nounswc.png\"))\n",
    "\n",
    "# show\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a183487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"img/nounswc.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c96d543",
   "metadata": {},
   "source": [
    "But we also want to know, which named entities are in the questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fe3f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the named entities in the Doc object \n",
    "for ent in doc.ents:\n",
    "\n",
    "    # Print the named entity and its label\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53181ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import visualization tool from spacy, render the entities\n",
    "from spacy import displacy\n",
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736b28f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create file to be able to visualize the entities with word cloud\n",
    "# Attention: this file already exists. if you write it again, it adds more entities to the file\n",
    "for ent in doc.ents:\n",
    "    with open(\"txt/ents.txt\", \"a\") as myfile:\n",
    "        myfile.write(ent.text + \"\\n\")    \n",
    "        print(ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fa419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = path.dirname(__file__) if \"__file__\" in locals() else os.getcwd()\n",
    "\n",
    "wctext = open(path.join(d, 'txt/ents.txt')).read()\n",
    "\n",
    "alice_mask = np.array(Image.open(path.join(d, \"img/alice_mask.png\")))\n",
    "\n",
    "wc = WordCloud(background_color=\"white\", max_words=2000, mask=alice_mask, contour_width=3, contour_color='red')\n",
    "\n",
    "wc.generate(wctext)\n",
    "\n",
    "wc.to_file(path.join(d, \"img/entswc.png\"))\n",
    "\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6717a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"img/entswc.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323d5bf4",
   "metadata": {},
   "source": [
    "Let's see, if a different tool for NLP recognizes the named entities better:\n",
    "\n",
    "Booknlp by David Bammen: https://github.com/booknlp/booknlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84936e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"img/booknlp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3096d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from booknlp.booknlp import BookNLP\n",
    "\n",
    "model_params={\n",
    "\t\t\"pipeline\":\"entity,quote,supersense,event,coref\", \n",
    "\t\t\"model\":\"big\"\n",
    "\t}\n",
    "\t\n",
    "booknlp=BookNLP(\"en\", model_params)\n",
    "\n",
    "# Input file to process\n",
    "input_file=\"txt/questions.txt\"\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory=\"txt/booknlp/\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id=\"alice\"\n",
    "\n",
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f417ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open file where I extracted the nominals and the propers\n",
    "with open('txt/entities_booknlp.txt', 'r', encoding='UTF-8') as ebnlp:\n",
    "    ent_booklnp = ebnlp.read()\n",
    "    print(ent_booklnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65ea220",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = path.dirname(__file__) if \"__file__\" in locals() else os.getcwd()\n",
    "\n",
    "#open file where I extracted the entities from entities_booknlp.txt\n",
    "wctext = open(path.join(d, 'txt/booknlp.txt')).read()\n",
    "\n",
    "alice_mask = np.array(Image.open(path.join(d, \"img/alice_mask.png\")))\n",
    "\n",
    "wc = WordCloud(background_color=\"white\", max_words=2000, mask=alice_mask, contour_width=3, contour_color='green')\n",
    "\n",
    "wc.generate(wctext)\n",
    "\n",
    "wc.to_file(path.join(d, \"img/booknlpwc.png\"))\n",
    "\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4576b728",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"img/booknlpwc.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ac843a",
   "metadata": {},
   "source": [
    "## For The Future\n",
    "\n",
    "- Optimize: Working with text to get the right pattern to extract just the questions - also what are questions on a professional linguistic level?, French - use different language model?, mistakes in detecting nouns (e.g. \"queer\") and named entities (e.g. \"Duchess\"= work of art) - larger language model or training with other/larger corpus?, use Prodigy?\n",
    "\n",
    "\n",
    "- How many questions are there in each chapter?\n",
    "\n",
    "\n",
    "- Finding out who is asking who about what -  visualisation with graph modeling tool neo4j?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
